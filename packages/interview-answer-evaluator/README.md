# interview-answer-evaluator

[![npm version](https://img.shields.io/npm/v/interview-answer-evaluator.svg)](https://www.npmjs.com/package/interview-answer-evaluator)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> Rule-based evaluation of interview answers with STAR method analysis

A TypeScript library for evaluating interview answers using rule-based analysis. Supports general, technical, and behavioral interview types with STAR method (Situation, Task, Action, Result) detection.

**Currently optimized for Japanese language**, but can be extended for other languages.

## Features

- ğŸ“Š **Multi-criteria evaluation**: Length, specificity, structure, and STAR elements
- ğŸ¯ **Interview type support**: General, technical, and behavioral interviews
- ğŸ”¤ **Japanese language optimized**: Built-in patterns for Japanese text analysis
- ğŸ“ **Actionable feedback**: Returns both positive aspects and improvement suggestions
- ğŸ§ª **Well-tested**: Comprehensive test coverage

## Installation

```bash
npm install interview-answer-evaluator
```

## Usage

```typescript
import { evaluateAnswer, scoreToLevel, scoreToLabel } from 'interview-answer-evaluator';

// Evaluate an answer
const result = evaluateAnswer(
  "ç§ã¯3å¹´é–“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã€ãƒãƒ¼ãƒ ãƒªãƒ¼ãƒ€ãƒ¼ã¨ã—ã¦10åã®ãƒ¡ãƒ³ãƒãƒ¼ã‚’ç‡ã„ã€å£²ä¸Šã‚’20%å‘ä¸Šã•ã›ã¾ã—ãŸã€‚",
  "behavioral"
);

console.log(result.overallScore); // 0-100
console.log(result.scores);       // { length, specificity, structure, starElements }
console.log(result.positives);    // ["STARæ³•ã®è¦ç´ ãŒå«ã¾ã‚Œã¦ã„ã¾ã™", ...]
console.log(result.improvements); // ["ã‚‚ã†å°‘ã—è©³ã—ãèª¬æ˜ã™ã‚‹ã¨è‰¯ã„ã§ã—ã‚‡ã†", ...]

// Convert score to level (1-5)
const level = scoreToLevel(result.overallScore);
console.log(level); // 4

// Get human-readable label
const label = scoreToLabel(result.overallScore);
console.log(label); // "è‰¯ã„"
```

## API

### `evaluateAnswer(answer: string, interviewType: InterviewType): AnswerEvaluationResult`

Evaluates an interview answer and returns detailed scores and feedback.

**Parameters:**
- `answer`: The answer text to evaluate
- `interviewType`: `"general"` | `"technical"` | `"behavioral"`

**Returns:** `AnswerEvaluationResult`
```typescript
{
  overallScore: number;  // 0-100
  scores: {
    length: number;       // Appropriateness of answer length
    specificity: number;  // Presence of specific examples, numbers
    structure: number;    // Logical structure
    starElements: number; // STAR method elements
  };
  positives: string[];    // Positive aspects
  improvements: string[]; // Areas for improvement
}
```

### `scoreToLevel(score: number): number`

Converts a score (0-100) to a level (1-5).

| Score Range | Level |
|-------------|-------|
| 90-100 | 5 |
| 75-89 | 4 |
| 55-74 | 3 |
| 35-54 | 2 |
| 0-34 | 1 |

### `scoreToLabel(score: number): string`

Returns a Japanese label for the score level.

| Score Range | Label |
|-------------|-------|
| 90-100 | ç´ æ™´ã‚‰ã—ã„ |
| 75-89 | è‰¯ã„ |
| 55-74 | ã¾ãšã¾ãš |
| 35-54 | æ”¹å–„ã®ä½™åœ°ã‚ã‚Š |
| 0-34 | è¦ç·´ç¿’ |

## Evaluation Weights by Interview Type

| Interview Type | Length | Specificity | Structure | STAR Elements |
|---------------|--------|-------------|-----------|---------------|
| General | 25% | 30% | 25% | 20% |
| Technical | 20% | 35% | 25% | 20% |
| Behavioral | 15% | 25% | 20% | 40% |

## Extending for Other Languages

The library uses pattern matching for analysis. To support other languages, you can fork and modify the pattern constants in the source code:

- `STAR_PATTERNS`: Patterns for detecting STAR elements
- `SPECIFICITY_PATTERNS`: Patterns for detecting specific examples
- `STRUCTURE_PATTERNS`: Patterns for detecting logical structure

## License

MIT



